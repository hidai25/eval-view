# EvalView Environment Configuration
# Copy this file to .env and fill in your values:
#   cp .env.example .env

# OpenAI API Key (required for LLM-as-judge evaluation)
# Get yours at: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here

# Optional: Anthropic API Key (for Claude-based evaluation)
# ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Optional: Custom model for LLM-as-judge (default: gpt-4o-mini)
# EVALVIEW_JUDGE_MODEL=gpt-4o

# Optional: Enable debug logging
# DEBUG=1

# ============================================
# Telemetry (for EvalView maintainers only)
# ============================================

# PostHog API key for anonymous usage analytics
# POSTHOG_API_KEY=phc_your_key_here

# Disable telemetry collection
# EVALVIEW_TELEMETRY_DISABLED=1
